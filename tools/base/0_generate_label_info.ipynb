{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "from mmengine import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由GEN-VLKT提供\n",
    "from hico_text_label import hico_hoi_text_label, hico_obj_text_label  # no-inter 排在中间"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_ins: 90, len_ins_valid: 80\n"
     ]
    }
   ],
   "source": [
    "ins_labels = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', \n",
    "    'traffic light', 'fire hydrant', '', 'stop sign', 'parking meter', 'bench', 'bird', \n",
    "    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', '', \n",
    "    'backpack', 'umbrella', '', '', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', \n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', \n",
    "    'surfboard', 'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife', \n",
    "    'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', \n",
    "    'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', '', \n",
    "    'dining table', '', '', 'toilet', '', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', '', 'book', \n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "ann_ins_ids = (  # COCO 格式\n",
    "    1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, \n",
    "    23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, \n",
    "    48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, \n",
    "    73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90)\n",
    "print(f'len_ins: {len(ins_labels)}, len_ins_valid: {len(ann_ins_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'person', 'text': 'a photo of a person', 'valid_id': 0, 'ann_id': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_info = {\n",
    "    ann_id: {\n",
    "        'name': ins_labels[ann_id-1],\n",
    "        'text': text,\n",
    "\n",
    "        'valid_id': valid_id,\n",
    "        'ann_id'  : ann_id,\n",
    "    }\n",
    "    for ann_id, (valid_id, text) in zip(ann_ins_ids, hico_obj_text_label)\n",
    "}\n",
    "ins_info[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "rel_labels = [\n",
    "    'adjust', 'assemble', 'block', 'blow', 'board', 'break', 'brush_with', 'buy', 'carry', \n",
    "    'catch', 'chase', 'check', 'clean', 'control', 'cook', 'cut', 'cut_with', 'direct', \n",
    "    'drag', 'dribble', 'drink_with', 'drive', 'dry', 'eat', 'eat_at', 'exit', 'feed', \n",
    "    'fill', 'flip', 'flush', 'fly', 'greet', 'grind', 'groom', 'herd', 'hit', 'hold', \n",
    "    'hop_on', 'hose', 'hug', 'hunt', 'inspect', 'install', 'jump', 'kick', 'kiss', 'lasso', \n",
    "    'launch', 'lick', 'lie_on', 'lift', 'light', 'load', 'lose', 'make', 'milk', 'move', \n",
    "\n",
    "    'no_interaction',  # 需要在valid_id中将其挪到最后\n",
    "\n",
    "    'open', 'operate', 'pack', 'paint', 'park', 'pay', 'peel', 'pet', \n",
    "    'pick', 'pick_up', 'point', 'pour', 'pull', 'push', 'race', 'read', 'release', 'repair', \n",
    "    'ride', 'row', 'run', 'sail', 'scratch', 'serve', 'set', 'shear', 'sign', 'sip', \n",
    "    'sit_at', 'sit_on', 'slide', 'smell', 'spin', 'squeeze', 'stab', 'stand_on', \n",
    "    'stand_under', 'stick', 'stir', 'stop_at', 'straddle', 'swing', 'tag', 'talk_on', \n",
    "    'teach', 'text_on', 'throw', 'tie', 'toast', 'train', 'turn', 'type_on', 'walk', \n",
    "    'wash', 'watch', 'wave', 'wear', 'wield', 'zip'\n",
    "]\n",
    "print(len(rel_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'no_interaction', 'valid_id': 57, 'ann_id': 58}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_info = {\n",
    "    valid_id+1: {\n",
    "        'name': rel,\n",
    "        'valid_id': valid_id,\n",
    "        'ann_id'  : valid_id+1,\n",
    "    }\n",
    "    for valid_id, rel in enumerate(rel_labels)\n",
    "}\n",
    "rel_info[58]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把no-interaction移到最后，仅改变valid_id\n",
    "\n",
    "原本的排序非常影响loss计算和后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_rel_valid_id = 57  # no-interaction\n",
    "\n",
    "# 处理 rel_info\n",
    "rel_valid_id_map = [len(rel_info)] * len(rel_info)\n",
    "for info in rel_info.values():\n",
    "    new_valid_id = valid_id = info['valid_id']  # bg之前的不用管\n",
    "    if valid_id > bg_rel_valid_id:\n",
    "        info['valid_id'] = new_valid_id = valid_id - 1  # bg之后的往前移一位\n",
    "    elif valid_id == bg_rel_valid_id:\n",
    "        info['valid_id'] = new_valid_id = len(rel_info) - 1  # bg放到最后\n",
    "    rel_valid_id_map[new_valid_id] = valid_id\n",
    "\n",
    "# 处理 bg_rel_info\n",
    "new_bg_rel_valid_id = len(rel_info) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('valid_id_new2old_rel.npy', rel_valid_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rel_categories = [dict(id=int(id), name=info['name']) for id, info in rel_info.items()]\n",
    "rel_categories.sort(key=lambda cat: rel_info[cat['id']]['valid_id'])\n",
    "len(rel_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(rel_categories, 'rel_categories.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把no-interaction移到最后，并按[obj_name, rel_name]的字典序重新排列，仅改变valid_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_keys = list(hico_hoi_text_label.keys())\n",
    "new_keys = sorted(\n",
    "    raw_keys, \n",
    "    key=lambda x: [\n",
    "        x[0] == bg_rel_valid_id,  # 把no-interaction移到最后\n",
    "        ins_labels[ann_ins_ids[x[1]]-1],  # 按ins_name的字典序排列\n",
    "        rel_labels[x[0]]  # 按rel_name的字典序排列\n",
    "    ])\n",
    "hoi_valid_id_map = [raw_keys.index(key) for key in new_keys]\n",
    "new_hico_hoi_text_label = OrderedDict()\n",
    "for key in new_keys:\n",
    "    raw_valid_rel, raw_valid_obj = key\n",
    "    new_ann_rel = raw_valid_rel + 1\n",
    "    new_ann_ins = ann_ins_ids[raw_valid_obj]\n",
    "    new_key = (new_ann_rel, new_ann_ins)\n",
    "    new_hico_hoi_text_label[new_key] = hico_hoi_text_label[key]\n",
    "\n",
    "len(new_hico_hoi_text_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('valid_id_new2old_hoi.npy', hoi_valid_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'board-airplane',\n",
       " 'text': 'a photo of a person boarding an airplane',\n",
       " 'valid_id': 0,\n",
       " 'ann_id': 1,\n",
       " 'ann_hoi_pair': (5, 5),\n",
       " 'valid_hoi_pair': (4, 4),\n",
       " 'valid_rel_id': 4,\n",
       " 'ann_rel_id': 5,\n",
       " 'valid_obj_id': 4,\n",
       " 'ann_obj_id': 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoi_info = {}\n",
    "for valid_hoi, ((ann_rel, ann_obj), text) in enumerate(new_hico_hoi_text_label.items()):\n",
    "    ann_hoi = hoi_valid_id_map[valid_hoi] + 1\n",
    "    valid_rel = rel_info[ann_rel]['valid_id']\n",
    "    valid_obj = ins_info[ann_obj]['valid_id']\n",
    "\n",
    "    hoi_info[ann_hoi] = {\n",
    "        'name': f'{rel_info[ann_rel][\"name\"]}-{ins_info[ann_obj][\"name\"]}',\n",
    "        'text': text,\n",
    "\n",
    "        'valid_id'      : valid_hoi,\n",
    "        'ann_id'        : ann_hoi,\n",
    "\n",
    "        'ann_hoi_pair'  : (ann_rel, ann_obj),\n",
    "        'valid_hoi_pair': (valid_rel, valid_obj),\n",
    "\n",
    "        'valid_rel_id': valid_rel,\n",
    "        'ann_rel_id'  : ann_rel,\n",
    "\n",
    "        'valid_obj_id': valid_obj,\n",
    "        'ann_obj_id'  : ann_obj,\n",
    "    }\n",
    "hoi_info[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hoi_info = OrderedDict()\n",
    "for key in sorted(hoi_info.keys()):\n",
    "    new_hoi_info[key] = hoi_info[key]\n",
    "hoi_info = new_hoi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部分汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_info = {\n",
    "    'bg_rel' : {'ann_id': 58, 'valid_id': new_bg_rel_valid_id},\n",
    "    'ins_info': ins_info,\n",
    "    'rel_info': rel_info,\n",
    "    'hoi_info': hoi_info,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hoi到rel、obj的映射\n",
    "\n",
    "- 用于GEN-VLKT等直接用hoi标签做linear的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoi_info = label_info['hoi_info']\n",
    "valid_id_hoi2rel, valid_id_hoi2obj = [None]*len(hoi_info), [None]*len(hoi_info)\n",
    "for info in hoi_info.values():\n",
    "    valid_id_hoi2rel[info['valid_id']] = info['valid_rel_id']\n",
    "    valid_id_hoi2obj[info['valid_id']] = info['valid_obj_id']\n",
    "valid_id_hoi2rel = np.array(valid_id_hoi2rel, dtype=int)\n",
    "valid_id_hoi2obj = np.array(valid_id_hoi2obj, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('valid_id_hoi2rel.npy', valid_id_hoi2rel)\n",
    "np.save('valid_id_hoi2obj.npy', valid_id_hoi2obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合标签和组成标签的对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_utils(hoi_info, rel_info, ins_info):\n",
    "    \"\"\"只看ann_id\"\"\"\n",
    "    pair2hoi = {}\n",
    "    hois_per_obj = {i: [] for i in sorted(ins_info.keys())}\n",
    "    hois_per_rel = {i: [] for i in sorted(rel_info.keys())}\n",
    "    objs_per_rel = {i: [] for i in sorted(rel_info.keys())}\n",
    "    rels_per_obj = {i: [] for i in sorted(ins_info.keys())}\n",
    "\n",
    "    for key in sorted(list(hoi_info.keys())):\n",
    "        info = hoi_info[key]\n",
    "        pair2hoi[str(info['ann_hoi_pair'])] = key\n",
    "\n",
    "        ann_obj_id = info['ann_obj_id']\n",
    "        ann_rel_id = info['ann_rel_id']\n",
    "        hois_per_obj[ann_obj_id].append(key)\n",
    "        hois_per_rel[ann_rel_id].append(key)\n",
    "        objs_per_rel[ann_rel_id].append(ann_obj_id)\n",
    "        rels_per_obj[ann_obj_id].append(ann_rel_id)\n",
    "\n",
    "    def sort_value(dict_: dict):\n",
    "        for key, value in dict_.items():\n",
    "            dict_[key] = sorted(value)\n",
    "\n",
    "    sort_value(hois_per_obj)\n",
    "    sort_value(hois_per_rel)\n",
    "    sort_value(objs_per_rel)\n",
    "    sort_value(rels_per_obj)\n",
    "\n",
    "    return pair2hoi, hois_per_obj, hois_per_rel, objs_per_rel, rels_per_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair2hoi, hois_per_obj, hois_per_rel, objs_per_rel, rels_per_obj = \\\n",
    "    collect_utils(hoi_info, rel_info, ins_info)\n",
    "label_info.update({\n",
    "    'pair2hoi': pair2hoi,\n",
    "    'hois_per_obj': hois_per_obj,\n",
    "    'hois_per_rel': hois_per_rel,\n",
    "    'objs_per_rel': objs_per_rel,\n",
    "    'rels_per_obj': rels_per_obj,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(label_info, 'label_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只看valid_id\n",
    "valid_id_triplet2label = {\n",
    "    (0, info['valid_rel_id'], info['valid_obj_id']) : info['valid_id']\n",
    "    for info in label_info['hoi_info'].values()\n",
    "}\n",
    "valid_id_triplets = sorted(\n",
    "    list(valid_id_triplet2label.keys()), \n",
    "    key=lambda x: valid_id_triplet2label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(valid_id_triplet2label, 'valid_id_triplet2label.pkl')  # 0-base\n",
    "np.save('valid_id_triplets.npy', valid_id_triplets)  # 0-base  triplet_parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于排除错误组合的label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_info = load('../../configs/label_info.json')\n",
    "label_info = load('label_info.json')\n",
    "hoi_info = label_info['hoi_info']\n",
    "ins_info = label_info['ins_info']\n",
    "rel_info = label_info['rel_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sg_mat = np.zeros((len(ins_info), len(rel_info)), dtype=bool)\n",
    "for info in hoi_info.values():\n",
    "    correct_sg_mat[info['valid_obj_id'], info['valid_rel_id']] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('correct_sg_mat.npy', correct_sg_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sg_mat = np.zeros((len(ins_info), len(rel_info), len(ins_info)), dtype=bool)\n",
    "for info in hoi_info.values():\n",
    "    correct_sg_mat[0, info['valid_rel_id'], info['valid_obj_id']] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('correct_sg_mat_triplet.npy', correct_sg_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_info = load('../../configs/label_info.json')\n",
    "# label_info = load('label_info.json')\n",
    "hoi_info = label_info['hoi_info']\n",
    "ins_info = label_info['ins_info']\n",
    "rel_info = label_info['rel_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hico_unseen_index = {  # ann id\n",
    "    \"rare_first\": [  # 120\n",
    "        510, 280, 281, 403, 505, 287, 500, 499, 290, 486, 304, 312, 326,\n",
    "        440, 352, 359,  67, 428, 380, 419,  71, 417, 390,  91, 396,  77,\n",
    "        398,  85, 136, 263, 402, 593, 561, 587, 549, 594, 527, 182, 258,\n",
    "        540, 536, 261, 597, 346, 190, 206, 207, 430, 180, 351, 406, 523,\n",
    "        450, 262, 256, 547, 548,  45,  23, 335, 600, 240, 316, 318, 230,\n",
    "        159, 196, 239, 365, 223, 282, 150, 400,  84, 128, 255, 399, 404,\n",
    "        556, 553, 521, 532, 441, 437, 483, 275,   9, 189, 217, 598,  78,\n",
    "        408, 557, 470, 475, 108, 391, 411,  28, 382, 464, 100, 185, 101,\n",
    "        293, 518,  81, 334,  63, 355, 105,  56,  51, 199, 169, 392, 193,\n",
    "        596, 137, 582],\n",
    "    \"non_rare_first\": [  # 120\n",
    "         39,  42,  21,  19, 246,  12,  20, 155, 460,  43, 156, 140,  61,\n",
    "        462, 578, 154, 583,  90, 142, 577,  76, 213, 473,  62, 458, 147,\n",
    "        209,  95, 472, 132, 249, 545, 516, 567, 371, 482, 227, 251, 471,\n",
    "        324, 170, 481, 480, 231, 386,  74, 160, 191, 378, 177, 250, 372,\n",
    "        285,  49, 584,  54, 163, 141, 186, 107, 295,  57, 321, 153, 375,\n",
    "        339,  30, 595, 347, 457, 590,  46,  24,  68, 479, 224, 494, 229,\n",
    "        241, 216,  92, 116, 338, 560,   8, 219, 519, 298, 192, 267, 305,\n",
    "          7, 573, 530, 313,  10, 309, 418, 198, 194, 164, 456,  26,  55,\n",
    "        576, 447, 388, 484, 535, 341, 509, 111, 330, 247, 174, 507, 384,\n",
    "         94, 517,  65],\n",
    "    \"unseen_object\": [  # 100\n",
    "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
    "        125, 126, 127, 128, 129, 225, 226, 227, 228, 229, 230, 231, 232,\n",
    "        291, 292, 293, 294, 295, 314, 315, 316, 317, 318, 319, 320, 321,\n",
    "        322, 323, 324, 325, 337, 338, 339, 340, 341, 342, 419, 420, 421,\n",
    "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
    "        454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466,\n",
    "        467, 468, 469, 470, 471, 472, 473, 474, 534, 535, 536, 537, 538,\n",
    "        559, 560, 561, 562, 596, 597, 598, 599, 600],\n",
    "    \"unseen_verb\": [  # 84\n",
    "          5,   7,  13,  16,  19,  26,  35,  39,  41,  50,  59,  61,  69,\n",
    "         70,  73,  74,  78,  83,  97,  98, 105, 114, 117, 119, 123, 130,\n",
    "        140, 148, 151, 154, 166, 167, 173, 176, 177, 182, 191, 203, 211,\n",
    "        213, 220, 228, 229, 234, 236, 244, 299, 314, 316, 321, 327, 337,\n",
    "        343, 346, 355, 373, 402, 405, 410, 432, 437, 460, 467, 471, 473,\n",
    "        480, 482, 489, 492, 495, 499, 505, 520, 524, 536, 537, 542, 545,\n",
    "        563, 566, 570, 573, 592, 596],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 22, 24, 34, 35, 39, 41, 43, 59, 82, 85, 90]\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    sorted(list({hoi_info[str(i)]['ann_obj_id'] for i in \n",
    "                 hico_unseen_index['unseen_object']})), \n",
    "    compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 20, 27, 35, 39, 42, 43, 57, 63, 77, 80, 81, 85, 92, 93, 98, 100, 101, 107,\n",
      " 115]\n"
     ]
    }
   ],
   "source": [
    "pprint(\n",
    "    sorted(list({hoi_info[str(i)]['ann_rel_id'] for i in \n",
    "                 hico_unseen_index['unseen_verb']})), \n",
    "    compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correct mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sg_mat = np.load('../../configs/correct_sg_mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_first_mat = np.copy(correct_sg_mat)\n",
    "for ann_hoi in hico_unseen_index['rare_first']:\n",
    "    info = hoi_info.get(ann_hoi, hoi_info[str(ann_hoi)])\n",
    "    rare_first_mat[info['valid_obj_id'], info['valid_rel_id']] = False\n",
    "(correct_sg_mat != rare_first_mat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('correct_sg_mat_rare_first.npy', rare_first_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_rare_first_mat = np.copy(correct_sg_mat)\n",
    "for ann_hoi in hico_unseen_index['non_rare_first']:\n",
    "    info = hoi_info.get(ann_hoi, hoi_info[str(ann_hoi)])\n",
    "    non_rare_first_mat[info['valid_obj_id'], info['valid_rel_id']] = False\n",
    "(correct_sg_mat != non_rare_first_mat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('correct_sg_mat_non_rare_first.npy', non_rare_first_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_object_mat = np.copy(correct_sg_mat)\n",
    "for ann_hoi in hico_unseen_index['unseen_object']:\n",
    "    info = hoi_info.get(ann_hoi, hoi_info[str(ann_hoi)])\n",
    "    unseen_object_mat[info['valid_obj_id'], info['valid_rel_id']] = False\n",
    "(correct_sg_mat != unseen_object_mat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('correct_sg_mat_unseen_object.npy', unseen_object_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_verb_mat = np.copy(correct_sg_mat)\n",
    "for ann_hoi in hico_unseen_index['unseen_verb']:\n",
    "    info = hoi_info.get(ann_hoi, hoi_info[str(ann_hoi)])\n",
    "    unseen_verb_mat[info['valid_obj_id'], info['valid_rel_id']] = False\n",
    "(correct_sg_mat != unseen_verb_mat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('correct_sg_mat_unseen_verb.npy', unseen_verb_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pastas_train = load('../../annotations/pastas_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'category_id': '6-0', 'rel_ann_id': 1, 'image_id': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pastas_train['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "part_labels = [\n",
    "    'right_foot', 'right_leg', 'left_leg', 'left_foot', \n",
    "    'hip', 'head', \n",
    "    'right_hand', 'right_arm', 'left_arm', 'left_hand'\n",
    "]\n",
    "len(part_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'hip', 'valid_id': 4, 'ann_id': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "part_info = {\n",
    "    valid_id+1: {\n",
    "        'name': rel,\n",
    "        'valid_id': valid_id,\n",
    "        'ann_id'  : valid_id, \n",
    "    }\n",
    "    for valid_id, rel in enumerate(part_labels)\n",
    "}\n",
    "part_info[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arm': ['shoulder carry', 'be close to', 'hug', 'swing', 'no_interaction'],\n",
      " 'foot': ['stand on', 'tread on', 'walk with', 'walk to', 'run with', 'run to',\n",
      "          'dribble', 'kick', 'jump down', 'jump with', 'walk away',\n",
      "          'no_interaction'],\n",
      " 'hand': ['hold', 'carry', 'reach for', 'touch', 'put on', 'twist', 'wear',\n",
      "          'throw', 'throw out', 'write on', 'point with', 'point to',\n",
      "          'use something to point to', 'press', 'squeeze', 'scratch', 'pinch',\n",
      "          'gesture to', 'push', 'pull', 'pull with something', 'wash',\n",
      "          'wash with something', 'hold in both hands', 'lift',\n",
      "          'raise(over head)', 'feed', 'cut with something',\n",
      "          'catch with something', 'pour into', 'no_interaction'],\n",
      " 'head': ['eat', 'inspect', 'talk with something', 'talk to', 'be close with',\n",
      "          'kiss', 'put something over head', 'lick', 'blow', 'drink with',\n",
      "          'smell', 'wear', 'no_interaction'],\n",
      " 'hip': ['sit on', 'sit in', 'sit beside', 'be close with', 'no_interaction'],\n",
      " 'leg': ['walk with', 'walk to', 'run with', 'run to', 'jump with',\n",
      "         'is close with', 'straddle', 'jump down', 'walk away',\n",
      "         'no_interaction']}\n"
     ]
    }
   ],
   "source": [
    "state_info = defaultdict(list)\n",
    "with open('../../configs/Part_State_76.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        part, state = line.strip().split(': ')\n",
    "        state_info[part].append(state)\n",
    "state_info = dict(state_info)\n",
    "pprint(state_info, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pasta_categories = []\n",
    "for i, part in enumerate(part_labels):\n",
    "    part_split = part.split('_')\n",
    "    part = ' '.join(part_split)\n",
    "    for j, state in enumerate(state_info[part_split[-1]]):\n",
    "        pasta_categories.append(dict(\n",
    "            id=f'{i}-{j}',\n",
    "            part_name=part,\n",
    "            state_name=state,\n",
    "            part_id=i,\n",
    "            state_id=j,\n",
    "            name=f\"{part}-{state}\"\n",
    "        ))\n",
    "len(pasta_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0-0',\n",
       "  'part_name': 'right foot',\n",
       "  'state_name': 'stand on',\n",
       "  'part_id': 0,\n",
       "  'state_id': 0,\n",
       "  'name': 'right foot-stand on'},\n",
       " {'id': '0-1',\n",
       "  'part_name': 'right foot',\n",
       "  'state_name': 'tread on',\n",
       "  'part_id': 0,\n",
       "  'state_id': 1,\n",
       "  'name': 'right foot-tread on'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pasta_categories[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(pasta_categories, 'pasta_categories.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasta_info = {item['id']: item for item in pasta_categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0-0',\n",
       " 'part_name': 'right foot',\n",
       " 'state_name': 'stand on',\n",
       " 'part_id': 0,\n",
       " 'state_id': 0,\n",
       " 'name': 'right foot-stand on'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pasta_info['0-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_info = load('../../configs/label_info.json')\n",
    "label_info = load('label_info.json')\n",
    "label_info.update({\n",
    "    'part_info': part_info,\n",
    "    'state_info': state_info,\n",
    "    'pasta_info': pasta_info\n",
    "})\n",
    "dump(label_info, 'label_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "860f04aefc9e3b0aa81e6b65839e758c2f993e15969b910de4cd110e056d16fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
