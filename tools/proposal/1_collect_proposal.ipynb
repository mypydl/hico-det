{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mmcv import imread\n",
    "from mmengine import dump, load\n",
    "\n",
    "from utils import box_xywh2xyxy, box_xyxy2xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = load('../../annotations/image_info_train.json')\n",
    "test_img  = load('../../annotations/image_info_test.json')\n",
    "\n",
    "train_img_root = '../../images/train/'\n",
    "test_img_root = '../../images/test/'\n",
    "\n",
    "ins_categories = load('../../configs/ins_categories.json')\n",
    "coco_ins_label2cat = {i: cat['id'] for i, cat in enumerate(ins_categories)}\n",
    "coco_ins_cat2label = {cat['id']: i for i, cat in enumerate(ins_categories)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "palette = np.asarray([\n",
    "    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),\n",
    "    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30),\n",
    "    (165, 42, 42), (255, 77, 255), (0, 226, 252), (182, 182, 255),\n",
    "    (0, 82, 0), (120, 166, 157), (110, 76, 0), (174, 57, 255),\n",
    "    (199, 100, 0), (72, 0, 118), (255, 179, 240), (0, 125, 92),\n",
    "    (209, 0, 151), (188, 208, 182), (0, 220, 176), (255, 99, 164),\n",
    "    (92, 0, 73), (133, 129, 255), (78, 180, 255), (0, 228, 0),\n",
    "    (174, 255, 243), (45, 89, 255), (134, 134, 103), (145, 148, 174),\n",
    "    (255, 208, 186), (197, 226, 255), (171, 134, 1), (109, 63, 54),\n",
    "    (207, 138, 255), (151, 0, 95), (9, 80, 61), (84, 105, 51),\n",
    "    (74, 65, 105), (166, 196, 102), (208, 195, 210), (255, 109, 65),\n",
    "    (0, 143, 149), (179, 0, 194), (209, 99, 106), (5, 121, 0),\n",
    "    (227, 255, 205), (147, 186, 208), (153, 69, 1), (3, 95, 161),\n",
    "    (163, 255, 0), (119, 0, 170), (0, 182, 199), (0, 165, 120),\n",
    "    (183, 130, 88), (95, 32, 0), (130, 114, 135), (110, 129, 133),\n",
    "    (166, 74, 118), (219, 142, 185), (79, 210, 114), (178, 90, 62),\n",
    "    (65, 70, 15), (127, 167, 115), (59, 105, 106), (142, 108, 45),\n",
    "    (196, 172, 0), (95, 54, 80), (128, 76, 255), (201, 57, 1),\n",
    "    (246, 0, 122), (191, 162, 208)], dtype=float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(box, ax, info: dict = {}):\n",
    "    x, y, w, h = box\n",
    "\n",
    "    edgecolor = info.get('edgecolor', 'green')\n",
    "    name = info.get('name', '')\n",
    "\n",
    "    # ax.text(x0, y0, name, fontdict=font)\n",
    "    ax.text(x, y, name)\n",
    "    # 底色\n",
    "    ax.add_patch(plt.Rectangle((x, y), w, h, edgecolor='white', facecolor=(0,0,0,0), lw=2))\n",
    "    # 类别颜色\n",
    "    ax.add_patch(plt.Rectangle((x, y), w, h, edgecolor=edgecolor, facecolor=(0,0,0,0), lw=1))\n",
    "\n",
    "def watch_ins_proposal(proposal: dict, img_path: str, with_name: bool = True):\n",
    "    image = imread(img_path, channel_order='rgb')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(os.path.basename(img_path))\n",
    "    ax.axis('off')\n",
    "    bboxes = proposal['instances']['bboxes']\n",
    "    labels = proposal['instances']['labels']\n",
    "    for box, label in zip(bboxes, labels):\n",
    "        cat = coco_ins_label2cat[label]\n",
    "        info = dict(edgecolor=palette[label])\n",
    "        if with_name:\n",
    "            info['name'] = ins_categories[cat]['name']\n",
    "        show_box(box, ax, info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_mmdet_proposal(ins_pred: list, coco_img: dict, score_thr: float = 0.1):\n",
    "    \"\"\"从mmdet的预测转换\"\"\"\n",
    "    id2filename = {item['id']: item['file_name'] for item in coco_img['images']}\n",
    "\n",
    "    num_valid = 0\n",
    "    ins_proposals = defaultdict(lambda:{'bboxes': [], 'labels': [], 'scores': []})\n",
    "    for ins in tqdm(ins_pred):\n",
    "        if ins['score'] < score_thr:\n",
    "            continue\n",
    "        num_valid += 1\n",
    "        img_name = id2filename[ins['image_id']]\n",
    "        ins_proposals[img_name]['bboxes'].append(box_xywh2xyxy(ins['bbox']))\n",
    "        ins_proposals[img_name]['labels'].append(ins['category_id'])\n",
    "        ins_proposals[img_name]['scores'].append(ins['score'      ])\n",
    "    print('num valid:', num_valid)\n",
    "\n",
    "    total_proposals = {}\n",
    "    for filename, props in ins_proposals.items():\n",
    "        labels = props['labels']\n",
    "        if coco_ins_cat2label is not None:\n",
    "            labels = [coco_ins_cat2label[i] for i in labels]\n",
    "        ins_props = {\n",
    "            'bboxes': np.float32(props['bboxes']).round(0),\n",
    "            'scores': np.float32(props['scores']).round(3),\n",
    "            'labels': np.int64(labels),\n",
    "            'ids'   : np.arange(len(labels))  # 单张图内id\n",
    "        }\n",
    "\n",
    "        total_proposals[filename] = {'instances': ins_props}\n",
    "    return total_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_scg_proposal(root, ins_label_2_id_map: dict = None, \n",
    "                     score_thr: float = 0.1, human_id: int = 0):\n",
    "    \"\"\"从SCG系列（SCG, ViPLO, UPT）的proposal转换\"\"\"\n",
    "    total_proposals = {}\n",
    "    for filename in tqdm(os.listdir(root)):\n",
    "        props = load(os.path.join(root, filename))\n",
    "        img_name = filename.replace('.json', '.jpg')\n",
    "\n",
    "        labels = props['labels']\n",
    "        if ins_label_2_id_map is not None:\n",
    "            labels = [ins_label_2_id_map[i] for i in labels]\n",
    "\n",
    "        bboxes = np.float32(props['boxes' ]).round(0)  # xyxy\n",
    "        scores = np.float32(props['scores']).round(3)\n",
    "        labels = np.int64(labels)\n",
    "\n",
    "        keep = scores > score_thr\n",
    "        keep_human = keep[labels == human_id]\n",
    "\n",
    "        ins_props = {\n",
    "            'bboxes': bboxes[keep],\n",
    "            'scores': scores[keep],\n",
    "            'labels': labels[keep],\n",
    "            'ids'   : np.arange(keep.sum())  # 单张图内id\n",
    "        }\n",
    "\n",
    "        if 'human_joints' in props:\n",
    "            points = np.float32(props['human_joints']\n",
    "                                ).round(0).reshape(-1, 17, 2)\n",
    "            scores = np.float32(props['human_joints_score']\n",
    "                                ).round(3).reshape(-1, 17)\n",
    "            pose_props = {\n",
    "                'keypoints' : points[keep_human],\n",
    "                'scores'    : scores[keep_human],\n",
    "                'tgt_ins_id': np.where(ins_props['labels']==human_id)[0]\n",
    "            }\n",
    "\n",
    "            total_proposals[img_name] = {\n",
    "                'instances'       : ins_props, \n",
    "                'person_keypoints': pose_props\n",
    "            }\n",
    "        else:\n",
    "            total_proposals[img_name] = {'instances': ins_props}\n",
    "    return total_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_ins_ann2proposal(coco_ins: COCO):\n",
    "    proposals = dict()\n",
    "    for img_id in tqdm(coco_ins.getImgIds()):\n",
    "        img_info = coco_ins.loadImgs(img_id)[0]\n",
    "        ins_anns = coco_ins.loadAnns(sorted(coco_ins.getAnnIds(img_id)))\n",
    "\n",
    "        bboxes, labels = [], []\n",
    "        for ann in ins_anns:\n",
    "            bboxes.append(box_xywh2xyxy(ann['bbox']))\n",
    "            labels.append(coco_ins_cat2label[ann['category_id']])\n",
    "\n",
    "        proposals[img_info['file_name']] = {\n",
    "            'instances': {\n",
    "                'bboxes': np.float32(bboxes),\n",
    "                'scores': np.ones_like(labels, dtype=np.float32),\n",
    "                'labels': np.int64(labels),\n",
    "                'ids'   : np.arange(len(labels))  # 单张图内id\n",
    "            }\n",
    "        }\n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuhao/.conda/envs/torch2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wuhao/.conda/envs/torch2/lib/python3.9/site-packages/colossalai/kernel/cuda_native/mha/flash_attn_2.py:21: UserWarning: FlashAttention only supports Ampere GPUs or newer.\n",
      "  warnings.warn(\"FlashAttention only supports Ampere GPUs or newer.\")\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0)\n",
      "    Python  3.9.18 (you have 3.9.18)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "from mmengine.structures import InstanceData\n",
    "from mmpose.structures import PoseDataSample\n",
    "from mmpose.visualization import PoseLocalVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1,\n",
      "  'keypoints': ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
      "                'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
      "                'left_wrist', 'right_wrist', 'left_hip', 'right_hip',\n",
      "                'left_knee', 'right_knee', 'left_ankle', 'right_ankle'],\n",
      "  'name': 'person',\n",
      "  'skeleton': [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],\n",
      "               [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3],\n",
      "               [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]],\n",
      "  'supercategory': 'person'}]\n"
     ]
    }
   ],
   "source": [
    "pose_categories = load('../../configs/pose_categories.json')\n",
    "pprint(pose_categories, compact=True)\n",
    "\n",
    "dataset_meta = {'skeleton_links': pose_categories[0]['skeleton']}\n",
    "pose_local_visualizer = PoseLocalVisualizer(\n",
    "    link_color=tuple((255, 0, 0)) * len(dataset_meta['skeleton_links']),\n",
    "    line_width=4)\n",
    "pose_local_visualizer.set_dataset_meta(dataset_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_pose_proposal(proposal: dict, img_path: str):\n",
    "    visualizer = deepcopy(pose_local_visualizer)\n",
    "    image = imread(img_path, channel_order='rgb')\n",
    "    data = PoseDataSample()\n",
    "    keypoints = np.array(proposal['person_keypoints']['keypoints']).reshape(-1, 17, 3)\n",
    "    data.gt_instances = InstanceData(keypoints=keypoints)\n",
    "    vis_result = visualizer.add_datasample('image', image, data, draw_pred=False)\n",
    "    plt.imshow(vis_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person_from_proposal(ins_props: dict, coco_img: dict):\n",
    "    \"\"\"挑出“人”实例，用于姿态估计\"\"\"\n",
    "    filename2id = {item['file_name']: item['id'] for item in coco_img['images']}\n",
    "\n",
    "    human_ins = []\n",
    "    imgs_wo_human = []\n",
    "\n",
    "    for filename, prop in tqdm(ins_props.items()):\n",
    "        prop = prop['instances']\n",
    "        image_id = filename2id[filename]\n",
    "        wo_human = True\n",
    "        for label, bbox, score, id in zip(prop['labels'], prop['bboxes'], \n",
    "                                          prop['scores'], prop['ids'   ]):\n",
    "            if label == 0:\n",
    "                wo_human = False\n",
    "                human_ins.append({\n",
    "                    'image_id'   : image_id,\n",
    "                    'bbox'       : box_xyxy2xywh(bbox),\n",
    "                    'score'      : score,\n",
    "                    'category_id': 1,\n",
    "                    'id'         : id\n",
    "                })\n",
    "        if wo_human:\n",
    "            imgs_wo_human.append(image_id)\n",
    "\n",
    "    print('num person:', len(human_ins))\n",
    "    print('num image wo person:', len(imgs_wo_human))\n",
    "    return human_ins, imgs_wo_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并各种类型的proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pose_to_prop(proposals: dict, pose_pred: list, coco_img: dict) -> dict:\n",
    "    id2filename = {item['id']: item['file_name'] for item in coco_img['images']}\n",
    "\n",
    "    pose_proposals = defaultdict(list)\n",
    "    for pose in tqdm(pose_pred):\n",
    "        img_name = id2filename[pose['image_id']]\n",
    "        pose_proposals[img_name].append(pose['keypoints'])\n",
    "    pose_proposals = dict(pose_proposals)\n",
    "\n",
    "    print('num image:', len(set(proposals.keys())))\n",
    "    print('num image wo pose prop:', \n",
    "          len(set(proposals.keys()) ^ set(pose_proposals.keys())))\n",
    "\n",
    "    total_proposals = deepcopy(proposals)\n",
    "    for img_name, props in total_proposals.items():\n",
    "        if img_name not in pose_proposals:\n",
    "            # 没有person预测，也就没有pose预测\n",
    "            poses = np.zeros((0, 17, 3))\n",
    "        else:\n",
    "            poses = pose_proposals[img_name]\n",
    "            poses = np.array(poses, dtype=np.float32).reshape(-1, 17, 3)\n",
    "        props['person_keypoints'] = {\n",
    "            'keypoints': poses[..., :-1],\n",
    "            'scores'   : poses[...,  -1],\n",
    "            'tgt_ins_id': np.where(proposals[img_name]['instances']['labels']==0)[0]\n",
    "        }\n",
    "    return total_proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实际转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FasterRCNN(SCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_root = '../../proposals/SCG/'\n",
    "train_total_prop_path = os.path.join(proposal_root, 'proposal_scg_train.pkl')\n",
    "test_total_prop_path  = os.path.join(proposal_root, 'proposal_scg_test.pkl')\n",
    "train_ins_prop_root   = os.path.join(proposal_root, 'train2015')\n",
    "test_ins_prop_root    = os.path.join(proposal_root, 'test2015')\n",
    "train_pose_prop_path  = os.path.join(proposal_root, 'body2d_hico-train_scg.keypoints.json')\n",
    "test_pose_prop_path   = os.path.join(proposal_root, 'body2d_hico-test_scg.keypoints.json')\n",
    "train_person_path     = os.path.join(proposal_root, 'train_person.json')\n",
    "test_person_path      = os.path.join(proposal_root, 'test_person.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_ins_labels = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', \n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', \n",
    "    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', \n",
    "    'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', \n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', \n",
    "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', \n",
    "    'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', \n",
    "    'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', \n",
    "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', \n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "scg_ins_labels = [\n",
    "    'airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove',\n",
    "    'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl',\n",
    "    'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair',\n",
    "    'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant',\n",
    "    'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse',\n",
    "    'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle',\n",
    "    'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant',\n",
    "    'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink',\n",
    "    'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign',\n",
    "    'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster',\n",
    "    'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella',\n",
    "    'vase', 'wine glass', 'zebra']\n",
    "scg_ins_map = {}\n",
    "for i, key in enumerate(scg_ins_labels):\n",
    "    j = coco_ins_labels.index(key)\n",
    "    scg_ins_map[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37633 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37633/37633 [00:05<00:00, 7061.10it/s]\n",
      "100%|██████████| 9546/9546 [00:01<00:00, 6004.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# 转换proposal格式\n",
    "train_proposals = cvt_scg_proposal(train_ins_prop_root, scg_ins_map, score_thr=0.1)\n",
    "test_proposals  = cvt_scg_proposal( test_ins_prop_root, scg_ins_map, score_thr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_proposals = load(train_total_prop_path)\n",
    "# test_proposals  = load( test_total_prop_path)\n",
    "# len(train_proposals), len(test_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': {'bboxes': array([[208.,  26., 455., 321.],\n",
       "         [ 46., 101., 579., 397.]], dtype=float32),\n",
       "  'scores': array([1.   , 0.999], dtype=float32),\n",
       "  'labels': array([0, 3]),\n",
       "  'ids': array([0, 1])}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proposals['HICO_train2015_00000001.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### person_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37633 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37633/37633 [00:01<00:00, 32375.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 220261\n",
      "num image wo person: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9546/9546 [00:00<00:00, 23077.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 54433\n",
      "num image wo person: 19\n"
     ]
    }
   ],
   "source": [
    "# 提取仅含“人”的实例\n",
    "train_person, train_imgs_wo_human = extract_person_from_proposal(train_proposals, train_img)\n",
    "test_person ,  test_imgs_wo_human = extract_person_from_proposal( test_proposals,  test_img)\n",
    "dump(train_person, train_person_path)\n",
    "dump( test_person,  test_person_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_person = load(train_person_path)\n",
    "# test_person  = load( test_person_path)\n",
    "# len(train_person), len(test_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 16930, 'bbox': [63.0, 115.0, 30.0, 62.0], 'score': 0.365, 'category_id': 1, 'id': 11}\n"
     ]
    }
   ],
   "source": [
    "print(train_person[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取姿态估计结果\n",
    "train_pose = load(train_pose_prop_path)\n",
    "test_pose  = load( test_pose_prop_path)\n",
    "assert len(train_pose) == len(train_person), f'{len(train_pose)} != {len(train_person)}'\n",
    "assert len( test_pose) == len( test_person), f'{len( test_pose)} != {len( test_person)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成keypoints_proposal\n",
    "train_proposals = merge_pose_to_prop(train_proposals, train_pose, train_img)\n",
    "test_proposals  = merge_pose_to_prop( test_proposals,  test_pose,  test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(train_proposals, train_total_prop_path)\n",
    "dump( test_proposals,  test_total_prop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPT(ViPLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_root = '../../proposals/ViPLO/'\n",
    "train_total_prop_path = os.path.join(proposal_root, 'proposal_viplo_train.pkl')\n",
    "test_total_prop_path  = os.path.join(proposal_root, 'proposal_viplo_test.pkl')\n",
    "train_ins_prop_root   = os.path.join(proposal_root, 'train2015_vitpose')\n",
    "test_ins_prop_root    = os.path.join(proposal_root, 'test2015_upt_vitpose')\n",
    "# train_pose_prop_path  = os.path.join(proposal_root, 'body2d_hico-train_upt.keypoints.json')  # 含在train_ins_prop_root中\n",
    "# test_pose_prop_path   = os.path.join(proposal_root, 'body2d_hico-test_upt.keypoints.json')\n",
    "train_person_path     = os.path.join(proposal_root, 'train_person.json')\n",
    "test_person_path      = os.path.join(proposal_root, 'test_person.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instance & person_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37633 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37633/37633 [00:24<00:00, 1532.15it/s]\n",
      "100%|██████████| 9546/9546 [00:06<00:00, 1578.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# 转换proposal格式\n",
    "train_proposals = cvt_scg_proposal(train_ins_prop_root, scg_ins_map, score_thr=0.1)\n",
    "test_proposals  = cvt_scg_proposal( test_ins_prop_root, scg_ins_map, score_thr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_proposals = load(train_total_prop_path)\n",
    "# test_proposals  = load( test_total_prop_path)\n",
    "# len(train_proposals), len(test_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': {'bboxes': array([[ 54.,  82., 581., 404.],\n",
       "         [212.,  37., 438., 295.]], dtype=float32),\n",
       "  'scores': array([0.999, 0.986], dtype=float32),\n",
       "  'labels': array([3, 0]),\n",
       "  'ids': array([0, 1])},\n",
       " 'person_keypoints': {'keypoints': array([[[401., 101.],\n",
       "          [407.,  93.],\n",
       "          [394.,  92.],\n",
       "          [412.,  89.],\n",
       "          [371.,  77.],\n",
       "          [384., 108.],\n",
       "          [323.,  96.],\n",
       "          [424., 138.],\n",
       "          [311., 162.],\n",
       "          [415., 165.],\n",
       "          [370., 174.],\n",
       "          [303., 160.],\n",
       "          [249., 142.],\n",
       "          [349., 194.],\n",
       "          [283., 164.],\n",
       "          [327., 280.],\n",
       "          [238., 255.]]], dtype=float32),\n",
       "  'scores': array([[0.842, 0.897, 0.953, 0.391, 0.822, 0.423, 0.85 , 0.335, 0.917,\n",
       "          0.418, 0.792, 0.466, 0.769, 0.4  , 0.737, 0.369, 0.828]],\n",
       "        dtype=float32),\n",
       "  'tgt_ins_id': array([1])}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_proposals['HICO_train2015_00000001.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37633/37633 [00:02<00:00, 16419.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 376085\n",
      "num image wo person: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9546/9546 [00:00<00:00, 45665.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person: 82428\n",
      "num image wo person: 3\n"
     ]
    }
   ],
   "source": [
    "# 提取仅含“人”的实例\n",
    "train_person, train_imgs_wo_human = extract_person_from_proposal(train_proposals, train_img)\n",
    "test_person ,  test_imgs_wo_human = extract_person_from_proposal( test_proposals,  test_img)\n",
    "dump(train_person, train_person_path)\n",
    "dump( test_person,  test_person_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_person = load(train_person_path)\n",
    "# test_person  = load( test_person_path)\n",
    "# len(train_person), len(test_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 21540, 'bbox': [287.0, 116.0, 25.0, 35.0], 'score': 0.107, 'category_id': 1, 'id': 81}\n"
     ]
    }
   ],
   "source": [
    "print(train_person[100])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 获取姿态估计结果\n",
    "train_pose = load(train_pose_prop_path)\n",
    "test_pose  = load( test_pose_prop_path)\n",
    "assert len(train_pose) == len(train_person), f'{len(train_pose)} != {len(train_person)}'\n",
    "assert len( test_pose) == len( test_person), f'{len( test_pose)} != {len( test_person)}'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 转换成keypoints_proposal\n",
    "train_proposals = merge_pose_to_prop(train_proposals, train_pose, train_img)\n",
    "test_proposals  = merge_pose_to_prop( test_proposals,  test_pose,  test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(train_proposals, train_total_prop_path)\n",
    "dump( test_proposals,  test_total_prop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_root = '../../proposals/GT/'\n",
    "train_total_prop_path = os.path.join(proposal_root, 'proposal_gt_train.pkl')\n",
    "test_total_prop_path  = os.path.join(proposal_root, 'proposal_gt_test.pkl')\n",
    "train_pose_prop_path  = os.path.join(proposal_root, 'body2d_hico-train_gt.keypoints.json')\n",
    "test_pose_prop_path   = os.path.join(proposal_root, 'body2d_hico-test_gt.keypoints.json')\n",
    "train_person_path     = os.path.join(proposal_root, 'train_person.json')\n",
    "test_person_path      = os.path.join(proposal_root, 'test_person.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.26s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_ins = COCO('../../annotations/instances_train.json')\n",
    "test_ins  = COCO('../../annotations/instances_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2952/37633 [00:00<00:01, 29512.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37633/37633 [00:01<00:00, 33542.84it/s]\n",
      "100%|██████████| 9546/9546 [00:00<00:00, 28599.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# 转换成proposal\n",
    "train_proposals = cvt_ins_ann2proposal(train_ins)\n",
    "test_proposals  = cvt_ins_ann2proposal( test_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_proposals = load(train_total_prop_path)\n",
    "# test_proposals  = load( test_total_prop_path)\n",
    "# len(train_proposals), len(test_proposals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### person_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37633/37633 [00:01<00:00, 23075.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person:  109336\n",
      "num image wo person:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9546/9546 [00:00<00:00, 31995.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num person:  30896\n",
      "num image wo person:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 提取仅含“人”的实例\n",
    "train_person, train_imgs_wo_human = extract_person_from_proposal(train_proposals, train_img)\n",
    "test_person ,  test_imgs_wo_human = extract_person_from_proposal( test_proposals,  test_img)\n",
    "dump(train_person, train_person_path)\n",
    "dump( test_person,  test_person_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109336, 30896)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_person = load(train_person_path)\n",
    "# test_person  = load( test_person_path)\n",
    "# len(train_person), len(test_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 196, 'bbox': [274, 45, 98, 170], 'area': 16660, 'category_id': 1, 'image_id': 44, 'score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(train_person[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取姿态估计结果\n",
    "train_pose = load(train_pose_prop_path)\n",
    "test_pose  = load( test_pose_prop_path)\n",
    "assert len(train_pose) == len(train_person), f'{len(train_pose)} != {len(train_person)}'\n",
    "assert len( test_pose) == len( test_person), f'{len( test_pose)} != {len( test_person)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109336/109336 [00:00<00:00, 503601.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image: 37633\n",
      "num image wo pose prop: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30896/30896 [00:00<00:00, 495331.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num image: 9546\n",
      "num image wo pose prop: 0\n"
     ]
    }
   ],
   "source": [
    "# 转换成keypoints_proposal\n",
    "train_proposals = merge_pose_to_prop(train_proposals, train_pose, train_img)\n",
    "test_proposals  = merge_pose_to_prop( test_proposals,  test_pose,  test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(train_proposals, train_total_prop_path)\n",
    "dump( test_proposals,  test_total_prop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
